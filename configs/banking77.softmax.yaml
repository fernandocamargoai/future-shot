seed_everything: 42
trainer:
  max_epochs: 100
  precision: 16-mixed
  callbacks:
    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        monitor: val/loss
        patience: 3
        verbose: True
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val/loss
        verbose: True
  enable_checkpointing: False
  logger:
    class_path: pytorch_lightning.loggers.wandb.WandbLogger
    init_args:
      project: future-shot-banking77
      log_model: True

data:
  batch_size: 8
  dataset: banking77
  num_workers: 0
  preprocessing_fn:
    class_path: future_shot.extra.transformer.preprocessing.TokenizationFutureShotPreprocessing
    init_args:
      tokenizer: sentence-transformers/paraphrase-mpnet-base-v2
      text_field: text
      max_length: 128
model:
  class_path: future_shot.lightning.SoftmaxLightningModule
  init_args:
    encoder:
      class_path: sentence_transformers.SentenceTransformer
      init_args:
        model_name_or_path: sentence-transformers/paraphrase-mpnet-base-v2
    embedding_dim: 768
    num_classes: 77
    loss:
      class_path: torch.nn.CrossEntropyLoss

optimizer:
  class_path: torch.optim.RAdam
  init_args:
    lr: 0.00001

